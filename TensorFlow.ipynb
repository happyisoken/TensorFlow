{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ff0fcb-4b79-463d-9beb-73cdfe0e700a",
   "metadata": {},
   "source": [
    "#### TensorFlow\n",
    "\n",
    "TensorFlow is a deep learning library, developed by Google, that allows us to create fairly complicated models with little coding.\n",
    "\n",
    "#### TensorFlow Outline\n",
    "\n",
    "There are Python libraries tailored for Machine learning - TensorFlow and Sklearn.\n",
    "\n",
    "Scalar -> Vector -> Matrix -> Tensor  \n",
    "\n",
    "Which are Scalar -tensor,rank:0, Vector - tensor, rank:1 and Matrix - tensor,rank:2 respectively\n",
    "\n",
    "Tensors are simply a generalization of the concepts we have seen so far.\n",
    "\n",
    "##### TensorFlow vs Sklearn\n",
    "\n",
    "The TensorFlow package was developed by google to meet their needs internally. It was released to the public at the end of 2015. It is currently the leading library for neural networks, including deep, convolusion and recurrent neural networks. \n",
    "\n",
    "The advantage of TensorFlow is that, it uses both the CPU and the GPU of the computer. This crucial for the speed of the algorithms and it is done automatically. \n",
    "\n",
    "Google recently futhered the strength by introducing the TPU (Tensor Processing Units) which improves performance faster.\n",
    "\n",
    "An alternative to TensorFlow is Sklearn. However, it does not offer the same functionality as TensorFlow regarding neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208451f5-265c-4f00-8925-834dcf4748fb",
   "metadata": {},
   "source": [
    "#### TensorFlow 2 Intro\n",
    "\n",
    "###### History of Development(2015)\n",
    "\n",
    "TF1: This is one of the most widely used packages because of its versitility. It is also open source(free). A major drawback is that it is very hard to learn. \n",
    "\n",
    "This led to the develpment of higher level packages such as Pytouch and Keras.\n",
    "\n",
    "Keras: As at 2017, it was integrated in the tensorflow. Also open source. It is conceived as an interface for TensorFlow rather than a different library making the integration easier to digest and implement. \n",
    "\n",
    "TF2.0: It came into existence in 2019. It is a higher level programming than TF1. It is already adopted and loved as it was borrowed from Keras. TF2 is basically Keras. \n",
    "\n",
    "###### Advantages of TF2.0\n",
    "\n",
    "1. It is versatile. \n",
    "2. It is a higher level package than Keras.\n",
    "3. It has a simplified API.\n",
    "4. It has no duplicate and deprecated functions.\n",
    "5. It has added new functions.\n",
    "6. It boasts Eager execution i.e. allowing python's rules to apply to it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c450fe-d065-4cfe-af1a-5fe08e00f6bd",
   "metadata": {},
   "source": [
    "#### Minimal example with TensorFlow 2.0\n",
    "\n",
    "In this notebook we will recreate our machine learning algorithm using TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c762981-c365-4e5f-ba1b-118512022af5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13300\\607469456.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import the relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcca00b-99bc-44aa-af32-631c10437020",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cddfa07-44a5-45ca-9c1f-98b30f7a9728",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low = -10, high = 10, size = (observations, 1))\n",
    "zs = np.random.uniform(-10, 10, (observations, 1))\n",
    "\n",
    "generated_inputs = np.column_stack((xs, zs))\n",
    "\n",
    "noise = np.random.uniform(-1, 1, (observations, 1))\n",
    "\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "np.savez('TF_intro', inputs = generated_inputs, targets = generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb4d7cc-df30-48a3-bb48-2b1c2ecaa965",
   "metadata": {},
   "source": [
    "npz file allows NumPy's file type stores n-dimentional arrays. Tensors can be represented as n-dimensional arrays.\n",
    "\n",
    "data => preprocess => save in .npz which is used to buid the model instead of the original file.\n",
    "\n",
    "np.savez(file name, arrays) saves n-dimentional arrays in .npz format, using a certain keyword(label) for each array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24cd7d-8dc5-429c-a53f-465a03ea34db",
   "metadata": {},
   "source": [
    "#### Solving with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d800a-f7f9-4981-af29-f6d2eff769eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d52209-5051-4f1b-af38-21a3500f4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "#when employing tensorflow, we must actually BUILD the model\n",
    "#Building the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(output_size)\n",
    "                            ])\n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 0) #This will fit (train) the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8db255-67fb-4712-8998-ba35af367028",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "TF2.0 is based on keras, so that is the module needed to build a model.\n",
    "\n",
    "Sequential is the function that species how the model will be laid down('stacks layers')\n",
    "\n",
    "Linear combination + output = Layer.\n",
    "\n",
    "Output = np.dot(inputs, weights) + bias\n",
    "\n",
    "tf.keras.layers.Dense(output size) takes the inputs provided to the model and calculates the dot product of the inputs and the weights and adds the bias.\n",
    "\n",
    "model.compile(optimizer, loss) configures the model for training\n",
    "\n",
    "1. L2-norm loss = Least sum of squares (least sum of squared error)\n",
    "2. Scaling by #observations = average(mean)\n",
    "\n",
    "Epoch = iteration over the full dataset\n",
    "\n",
    "Verbose = 0 - stands for silent or no output about the trainin is diplayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d80dcfc-1e7d-4f86-9457-a1d05e564efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will set verbose = 1, stands for 'progress bar'\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "#when employing tensorflow, we must actually BUILD the model\n",
    "#Building the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(output_size)\n",
    "                            ])\n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea341c1-3d03-4890-be72-3ee49ef4b3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set verbose = 2, stands for 'one line per epoch'\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(output_size)\n",
    "                            ])\n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7330306e-6c9a-4a50-9131-777d8488abd8",
   "metadata": {},
   "source": [
    "#### Extract the weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace71cd3-ebf9-4426-a758-9a64c98b2b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a02e36-2dfd-47d0-84c2-4dd1e2dc6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82fe58-3d7b-4dfe-871b-14c5b2f85236",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = model.layers[0].get_weights()[1]\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5d545-0973-40f6-b152-a300c3b310ef",
   "metadata": {},
   "source": [
    "#### Extract the outputs (make predictions) \n",
    "\n",
    "model.predict_on_batch(data) calculates the outputs given inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f7193-c2b6-4ef5-8ce4-18863adb4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To predict the values with our model\n",
    "model.predict_on_batch(training_data['inputs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e1871-89f3-44eb-a46f-aa06acb94ce0",
   "metadata": {},
   "source": [
    "These are the values that were compared to the targets to evaluate the loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49281621-dcc3-4bbd-803c-33a246009cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rounding the values to 1\n",
    "model.predict_on_batch(training_data['inputs']).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35884a6-bcb7-4377-a592-c3a5f853bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing the targets of the outputs manually\n",
    "training_data['targets'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c7f05-718b-4d7a-b33e-bb8564b61abb",
   "metadata": {},
   "source": [
    "#### Plotting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4eea3a-e879-48c8-b533-1646cf7d3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf4f4f-1ede-42a2-87ef-3a1f0728b8a4",
   "metadata": {},
   "source": [
    "#### Plotting the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550313a2-af38-4e0f-8a22-4bbeb5275cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.reshape(observations,)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(xs, zs, targets)\n",
    "ax.set_xlabel('xs')\n",
    "ax.set_ylabel('zs')\n",
    "ax.set_zlabel('Targets')\n",
    "ax.view_init(azim=100)\n",
    "plt.show()\n",
    "targets = targets.reshape(observations,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d64e1-c982-4916-9e3a-e82a754e21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customizing your model\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(output_size),\n",
    "                                                kernel_initializer = tf.random_uniform_initializer(minval = -0.1, maxval = 0.1),\n",
    "                                                bias_initializer = tf.random_uniform_initializer(minval = -0.1, maxval = 0.1)\n",
    "                            ])\n",
    "\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate = 0.02)\n",
    "\n",
    "model.compile(optimizer = custom_optimizer, loss = 'mean_squared_error') # new result will be practically the same\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs = 100, verbose = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594afaf3-c432-4ef9-a426-bb18c9e28f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439465dc-7fd7-4116-a30d-3c519c6692e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
